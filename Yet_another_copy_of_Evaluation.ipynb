{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4lwyku6_CF8H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXsMAbsk06lt",
        "outputId": "301a8a71-739e-40eb-d33b-b261111aa9fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/deep learning project/latest\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/deep learning project/latest\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XsvoJxmE1aLD",
        "outputId": "c02270be-24ea-4b42-ebc8-ea693bf6107c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (4.51.3)\n",
            "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: peft>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.14.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.5.2)\n",
            "Requirement already satisfied: bitsandbytes>=0.41.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.45.5)\n",
            "Requirement already satisfied: trl>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.17.0)\n",
            "Requirement already satisfied: wandb>=0.15.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.19.9)\n",
            "Requirement already satisfied: evaluate>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.4.3)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (1.6.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 1)) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 1)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 2)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 2)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 2)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 2)) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 2)) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft>=0.6.0->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl>=0.7.2->-r requirements.txt (line 7)) (13.9.4)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.8->-r requirements.txt (line 8)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.8->-r requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.8->-r requirements.txt (line 8)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.8->-r requirements.txt (line 8)) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.8->-r requirements.txt (line 8)) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.8->-r requirements.txt (line 8)) (2.11.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.8->-r requirements.txt (line 8)) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.8->-r requirements.txt (line 8)) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.8->-r requirements.txt (line 8)) (75.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 11)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 11)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.15.8->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->-r requirements.txt (line 2)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->-r requirements.txt (line 2)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->-r requirements.txt (line 2)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->-r requirements.txt (line 2)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.0->-r requirements.txt (line 2)) (1.20.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.8->-r requirements.txt (line 8)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.15.8->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.15.8->-r requirements.txt (line 8)) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.15.8->-r requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.36.0->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.0->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.0->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.0->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl>=0.7.2->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl>=0.7.2->-r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.8->-r requirements.txt (line 8)) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl>=0.7.2->-r requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "#!pip install -q transformers peft datasets torch bitsandbytes accelerate\n",
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IEmytiUUdQ4G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iDqCaJPs4zUw"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2lGpChGu4781"
      },
      "outputs": [],
      "source": [
        "!pip install -q huggingface_hub\n",
        "from huggingface_hub import login\n",
        "login(token=hf_token)  # Will prompt for your Hugging Face token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YrhCxm6dYr7L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "import wandb\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "tfkEWnMr6Cqy"
      },
      "outputs": [],
      "source": [
        "def load_config(config_path=\"config.yaml\"):\n",
        "    \"\"\"Load configuration from YAML file\"\"\"\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VxEzKUe377At"
      },
      "outputs": [],
      "source": [
        "def prepare_tokenizer(config):\n",
        "    \"\"\"Prepare the tokenizer\"\"\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config['model']['name'])\n",
        "    #tokenizer = AutoTokenizer.from_pretrained(\"./model\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ysjaKGbs8Jhg"
      },
      "outputs": [],
      "source": [
        "def format_truthfulqa(example):\n",
        "    question = example['question']\n",
        "\n",
        "    # Use the first \"correct\" answer from the mc1_targets (label == 1)\n",
        "    correct_choices = [\n",
        "        choice for choice, label in zip(example[\"mc1_targets\"][\"choices\"], example[\"mc1_targets\"][\"labels\"]) if label == 1\n",
        "    ]\n",
        "    correct_answer = correct_choices[0] if correct_choices else \"\"\n",
        "\n",
        "    return {\"text\": f\"Question: {question}\\nAnswer: {correct_answer}\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-1eJwqwhHff"
      },
      "source": [
        "Loading TruthfulQA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4yFaYevU8Obl"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(tokenizer, config):\n",
        "    \"\"\"Prepare and tokenize the dataset with train/validation split\"\"\"\n",
        "    # Load TruthfulQA dataset\n",
        "    dataset = load_dataset(\"truthful_qa\", \"multiple_choice\")\n",
        "\n",
        "    # Format the dataset\n",
        "    formatted_dataset = dataset['validation'].map(format_truthfulqa)\n",
        "\n",
        "\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples[\"text\"],\n",
        "            truncation=True,\n",
        "            max_length=config['training']['max_length'],\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "\n",
        "    tokenized = formatted_dataset.map(tokenize_function, remove_columns=formatted_dataset.column_names, batched=True)\n",
        "    return tokenized, dataset['validation']  # second one is raw for extracting choices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKv_2GqEY8N9"
      },
      "source": [
        "Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aZByJAx4ADBE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nD_8SK59BrpK"
      },
      "outputs": [],
      "source": [
        "def load_model(config):\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        config['model']['name'],\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    model = PeftModel.from_pretrained(base_model, \"mistral-7b-triviaqa-lora_config3_v\")\n",
        "\n",
        "    #model.eval()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_Ma3e8naCpo"
      },
      "source": [
        "Evaluation with an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IJPVPL_raBI1"
      },
      "outputs": [],
      "source": [
        "def generate_answer(prompt, model, tokenizer, max_new_tokens=100):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYEgNBFLPOVX"
      },
      "source": [
        "Evaluation of the model using BLEU and ROUGE metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA6OmIIDPkue",
        "outputId": "db5f4c73-e219-433e-957c-09da6128d6e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "uow9rQPdt9Q-"
      },
      "outputs": [],
      "source": [
        "def extract_answer_letter(text):\n",
        "    \"\"\"\n",
        "    Extract the answer letter (A, B, C, etc.) from the model's output.\n",
        "\n",
        "    Args:\n",
        "        text (str): Text containing the model's generated answer\n",
        "\n",
        "    Returns:\n",
        "        str: The extracted answer letter or empty string if not found\n",
        "    \"\"\"\n",
        "    # Look for \"Answer:\" in the text\n",
        "    answer_start = text.find(\"Answer:\")\n",
        "    if answer_start == -1:\n",
        "        return \"\"\n",
        "\n",
        "    # Get the text after \"Answer:\"\n",
        "    answer_text = text[answer_start + len(\"Answer:\"):].strip()\n",
        "\n",
        "    # Try to extract the letter at the beginning of the answer\n",
        "    letter_pattern = r\"([A-Z])\\.\"\n",
        "    match = re.search(letter_pattern, answer_text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "\n",
        "    # If no letter with period found, try just the first letter\n",
        "    if answer_text and answer_text[0].isalpha():\n",
        "        return answer_text[0].upper()\n",
        "\n",
        "    return \"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BgP6dWfu_Hf5"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "IG_qUn406VSh"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, tokenizer, validation_data_raw):\n",
        "    rouge = evaluate.load(\"rouge\")\n",
        "    bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "    generated = []\n",
        "    references = []\n",
        "    correct_mc = 0\n",
        "    total_mc = 0\n",
        "\n",
        "    for example in tqdm(validation_data_raw, desc=\"Evaluating\"):\n",
        "        #print(f\"example: {example}\")\n",
        "        question = example[\"question\"]\n",
        "        #print(f\"question is {question}\")\n",
        "        correct_index = example[\"mc1_targets\"][\"labels\"].index(1)\n",
        "        #print(f\"correct_index is {correct_index}\")\n",
        "        choices = example[\"mc1_targets\"][\"choices\"]\n",
        "        #print(f\"choices: {choices}\")\n",
        "        choice_letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\"]  # Adjust if more options possible\n",
        "\n",
        "        # Format prompt\n",
        "        prompt = f\"Question: {question}\\nChoices:\\n\"\n",
        "        for i, choice in enumerate(choices):\n",
        "            prompt += f\"{choice_letters[i]}. {choice}\\n\"\n",
        "        prompt += \"Answer:\"\n",
        "\n",
        "        # Generate\n",
        "        output = generate_answer(prompt, model, tokenizer)\n",
        "        #print(f\"output: {output}\")\n",
        "\n",
        "        pred_letter = extract_answer_letter(output)\n",
        "        #print(f\"pred_letter: {pred_letter}\")\n",
        "\n",
        "\n",
        "        # Check if first letter of model's answer matches the correct label\n",
        "\n",
        "        correct_letter = choice_letters[correct_index]\n",
        "        #print(f\"correct_letter: {correct_letter}\")\n",
        "        if pred_letter == correct_letter:\n",
        "            correct_mc += 1\n",
        "        total_mc += 1\n",
        "        try:\n",
        "            pred_index = choice_letters.index(pred_letter) if pred_letter in choice_letters else -1\n",
        "            generated.append(choices[pred_index] if pred_index >= 0 and pred_index < len(choices) else \"\")\n",
        "        except ValueError:\n",
        "            generated.append(\"\")\n",
        "\n",
        "        references.append(choices[correct_index])\n",
        "    # Metrics\n",
        "    rouge_score = rouge.compute(predictions=generated, references=references)\n",
        "    bleu_score = bleu.compute(predictions=generated, references=[[ref] for ref in references])\n",
        "    mc_accuracy = correct_mc / total_mc\n",
        "\n",
        "    print(f\"\\n--- Evaluation Results ---\")\n",
        "    print(f\"MC Accuracy: {mc_accuracy:.4f}\")\n",
        "    print(f\"ROUGE-L: {rouge_score['rougeL']:.4f}\")\n",
        "    print(f\"BLEU: {bleu_score['bleu']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "24pA5BYzQq7U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b20c96fc8b924086adcefb42e00ae2d7",
            "cdb4bb7b0a7946468b8f9cb57838cb36",
            "3e60643c48d5416aa4df450e3f64a820",
            "af220d5076d443e7a49f1f5bdcab56e5",
            "042e06bc75b048fe83bec11f5e9083f9",
            "85475c51c6da4d098cb9520724186b9c",
            "59f74af3607e49568940e92eda8dee02",
            "31fffa461acf4e2fb22f050100aa772d",
            "bdf69a78f7b4470fb90bef324ebd1db9",
            "71468b43f8c14c7c8df7b975eab51cea",
            "2ed11fc1c51343b0aec0eeb5206fac34",
            "5e9cc19ed25a4a7daaeef79206401df4",
            "e6cb0840320a4ae9a2f1b5cbbd6355a0",
            "3b98693a4e0044cc8418ec3d03202f6a",
            "bd5e4865c7784eec8b47551b15def170",
            "7de49f8406764110a582df3fa1ab99bf",
            "48a6984ae23c42f98c606decece65a82",
            "c80025d206c24dc5ae2d27150c02c456",
            "d4e900527f464c489b11ad0f83d6d275",
            "8a5579d217b14066b7ff58a3093e1cd6",
            "0cd59236b9f2409a8acee19c010773f3",
            "127046adb4b74f49bf584d4883ebce4e"
          ]
        },
        "id": "LY8SAazO7k_k",
        "outputId": "e31e3588-f91e-463e-d6dc-26845b06b236"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b20c96fc8b924086adcefb42e00ae2d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/817 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e9cc19ed25a4a7daaeef79206401df4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   0%|          | 0/817 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   0%|          | 1/817 [00:06<1:30:29,  6.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   0%|          | 2/817 [00:13<1:30:47,  6.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   0%|          | 3/817 [00:19<1:30:22,  6.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   0%|          | 4/817 [00:26<1:30:19,  6.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   1%|          | 5/817 [00:33<1:30:20,  6.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   1%|          | 6/817 [00:40<1:30:04,  6.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   1%|          | 7/817 [00:46<1:29:35,  6.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   1%|          | 8/817 [00:53<1:29:20,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   1%|          | 9/817 [00:59<1:29:01,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   1%|          | 10/817 [01:06<1:28:47,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   1%|▏         | 11/817 [01:12<1:28:43,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   1%|▏         | 12/817 [01:19<1:28:23,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   2%|▏         | 13/817 [01:26<1:28:20,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   2%|▏         | 14/817 [01:32<1:28:06,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   2%|▏         | 15/817 [01:39<1:28:03,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   2%|▏         | 16/817 [01:45<1:27:54,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   2%|▏         | 17/817 [01:52<1:27:56,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   2%|▏         | 18/817 [01:59<1:27:51,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   2%|▏         | 19/817 [02:05<1:27:43,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   2%|▏         | 20/817 [02:12<1:27:37,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   3%|▎         | 21/817 [02:18<1:27:20,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   3%|▎         | 22/817 [02:25<1:27:23,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   3%|▎         | 23/817 [02:32<1:27:12,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   3%|▎         | 24/817 [02:38<1:27:06,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   3%|▎         | 25/817 [02:45<1:27:12,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   3%|▎         | 26/817 [02:51<1:27:04,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   3%|▎         | 27/817 [02:58<1:26:56,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   3%|▎         | 28/817 [03:04<1:22:48,  6.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   4%|▎         | 29/817 [03:10<1:23:49,  6.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   4%|▎         | 30/817 [03:17<1:24:26,  6.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   4%|▍         | 31/817 [03:23<1:25:08,  6.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   4%|▍         | 32/817 [03:30<1:25:20,  6.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   4%|▍         | 33/817 [03:31<1:03:10,  4.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   4%|▍         | 34/817 [03:37<1:09:57,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   4%|▍         | 35/817 [03:44<1:14:35,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   4%|▍         | 36/817 [03:51<1:17:45,  5.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   5%|▍         | 37/817 [03:57<1:19:57,  6.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   5%|▍         | 38/817 [04:04<1:21:32,  6.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   5%|▍         | 39/817 [04:10<1:22:37,  6.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   5%|▍         | 40/817 [04:17<1:23:15,  6.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   5%|▌         | 41/817 [04:23<1:23:42,  6.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   5%|▌         | 42/817 [04:30<1:23:58,  6.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   5%|▌         | 43/817 [04:37<1:24:25,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   5%|▌         | 44/817 [04:43<1:24:27,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   6%|▌         | 45/817 [04:50<1:24:24,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   6%|▌         | 46/817 [04:56<1:24:15,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   6%|▌         | 47/817 [05:03<1:24:16,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   6%|▌         | 48/817 [05:09<1:24:17,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   6%|▌         | 49/817 [05:16<1:24:25,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   6%|▌         | 50/817 [05:23<1:24:13,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   6%|▌         | 51/817 [05:29<1:24:01,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   6%|▋         | 52/817 [05:36<1:23:56,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   6%|▋         | 53/817 [05:42<1:23:43,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   7%|▋         | 54/817 [05:49<1:23:59,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   7%|▋         | 55/817 [05:56<1:23:43,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   7%|▋         | 56/817 [06:02<1:23:31,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   7%|▋         | 57/817 [06:09<1:23:20,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   7%|▋         | 58/817 [06:15<1:23:24,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   7%|▋         | 59/817 [06:22<1:23:10,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   7%|▋         | 60/817 [06:29<1:23:11,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   7%|▋         | 61/817 [06:35<1:23:13,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   8%|▊         | 62/817 [06:42<1:22:49,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   8%|▊         | 63/817 [06:48<1:22:47,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   8%|▊         | 64/817 [06:55<1:22:44,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   8%|▊         | 65/817 [07:02<1:22:28,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   8%|▊         | 66/817 [07:08<1:22:12,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   8%|▊         | 67/817 [07:15<1:22:06,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   8%|▊         | 68/817 [07:21<1:22:04,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   8%|▊         | 69/817 [07:28<1:21:56,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   9%|▊         | 70/817 [07:34<1:21:52,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   9%|▊         | 71/817 [07:41<1:21:48,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   9%|▉         | 72/817 [07:48<1:21:46,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   9%|▉         | 73/817 [07:54<1:21:36,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   9%|▉         | 74/817 [08:01<1:21:22,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   9%|▉         | 75/817 [08:07<1:21:11,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   9%|▉         | 76/817 [08:14<1:21:08,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:   9%|▉         | 77/817 [08:20<1:21:11,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  10%|▉         | 78/817 [08:27<1:21:03,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  10%|▉         | 79/817 [08:34<1:21:04,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  10%|▉         | 80/817 [08:40<1:20:54,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  10%|▉         | 81/817 [08:47<1:20:44,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  10%|█         | 82/817 [08:53<1:20:46,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  10%|█         | 83/817 [09:00<1:20:39,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  10%|█         | 84/817 [09:07<1:20:32,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  10%|█         | 85/817 [09:13<1:20:22,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  11%|█         | 86/817 [09:20<1:20:09,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  11%|█         | 87/817 [09:26<1:19:57,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  11%|█         | 88/817 [09:33<1:19:46,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  11%|█         | 89/817 [09:39<1:19:44,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  11%|█         | 90/817 [09:46<1:19:42,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  11%|█         | 91/817 [09:53<1:19:41,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  11%|█▏        | 92/817 [09:59<1:19:27,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  11%|█▏        | 93/817 [10:06<1:19:32,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  12%|█▏        | 94/817 [10:12<1:19:29,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  12%|█▏        | 95/817 [10:19<1:19:33,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  12%|█▏        | 96/817 [10:26<1:19:38,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  12%|█▏        | 97/817 [10:32<1:19:24,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  12%|█▏        | 98/817 [10:39<1:19:21,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  12%|█▏        | 99/817 [10:46<1:19:17,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  12%|█▏        | 100/817 [10:52<1:19:06,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  12%|█▏        | 101/817 [10:59<1:18:45,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  12%|█▏        | 102/817 [11:05<1:18:33,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  13%|█▎        | 103/817 [11:12<1:18:11,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  13%|█▎        | 104/817 [11:18<1:18:02,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  13%|█▎        | 105/817 [11:25<1:17:51,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  13%|█▎        | 106/817 [11:32<1:17:53,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  13%|█▎        | 107/817 [11:38<1:17:53,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  13%|█▎        | 108/817 [11:45<1:17:41,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  13%|█▎        | 109/817 [11:51<1:17:36,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  13%|█▎        | 110/817 [11:58<1:17:29,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  14%|█▎        | 111/817 [12:04<1:17:16,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  14%|█▎        | 112/817 [12:11<1:17:11,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  14%|█▍        | 113/817 [12:17<1:17:01,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  14%|█▍        | 114/817 [12:24<1:16:57,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  14%|█▍        | 115/817 [12:31<1:16:47,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  14%|█▍        | 116/817 [12:37<1:16:40,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  14%|█▍        | 117/817 [12:44<1:16:42,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  14%|█▍        | 118/817 [12:50<1:16:54,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  15%|█▍        | 119/817 [12:57<1:16:42,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  15%|█▍        | 120/817 [13:04<1:16:36,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  15%|█▍        | 121/817 [13:10<1:16:14,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  15%|█▍        | 122/817 [13:17<1:15:56,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  15%|█▌        | 123/817 [13:23<1:15:45,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  15%|█▌        | 124/817 [13:30<1:15:40,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  15%|█▌        | 125/817 [13:36<1:15:36,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  15%|█▌        | 126/817 [13:43<1:15:29,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  16%|█▌        | 127/817 [13:49<1:15:27,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  16%|█▌        | 128/817 [13:56<1:15:27,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  16%|█▌        | 129/817 [14:03<1:15:10,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  16%|█▌        | 130/817 [14:09<1:14:58,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  16%|█▌        | 131/817 [14:16<1:14:54,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  16%|█▌        | 132/817 [14:22<1:14:44,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  16%|█▋        | 133/817 [14:29<1:14:36,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  16%|█▋        | 134/817 [14:35<1:14:34,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  17%|█▋        | 135/817 [14:42<1:14:26,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  17%|█▋        | 136/817 [14:48<1:14:14,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  17%|█▋        | 137/817 [14:55<1:14:15,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  17%|█▋        | 138/817 [15:01<1:14:02,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  17%|█▋        | 139/817 [15:08<1:13:48,  6.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  17%|█▋        | 140/817 [15:15<1:13:48,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  17%|█▋        | 141/817 [15:21<1:13:44,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  17%|█▋        | 142/817 [15:28<1:13:35,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  18%|█▊        | 143/817 [15:34<1:13:24,  6.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  18%|█▊        | 144/817 [15:41<1:13:32,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  18%|█▊        | 145/817 [15:47<1:13:31,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  18%|█▊        | 146/817 [15:54<1:13:33,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  18%|█▊        | 147/817 [16:00<1:13:22,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  18%|█▊        | 148/817 [16:07<1:13:17,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  18%|█▊        | 149/817 [16:14<1:13:18,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  18%|█▊        | 150/817 [16:20<1:13:22,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  18%|█▊        | 151/817 [16:27<1:13:14,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  19%|█▊        | 152/817 [16:33<1:12:49,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  19%|█▊        | 153/817 [16:40<1:12:44,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  19%|█▉        | 154/817 [16:47<1:12:25,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  19%|█▉        | 155/817 [16:53<1:12:23,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  19%|█▉        | 156/817 [17:00<1:12:23,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  19%|█▉        | 157/817 [17:06<1:12:25,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  19%|█▉        | 158/817 [17:13<1:12:20,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  19%|█▉        | 159/817 [17:20<1:12:26,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  20%|█▉        | 160/817 [17:26<1:12:18,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  20%|█▉        | 161/817 [17:33<1:12:16,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  20%|█▉        | 162/817 [17:39<1:12:19,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  20%|█▉        | 163/817 [17:46<1:12:17,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  20%|██        | 164/817 [17:53<1:12:25,  6.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  20%|██        | 165/817 [17:59<1:12:14,  6.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  20%|██        | 166/817 [18:06<1:12:01,  6.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  20%|██        | 167/817 [18:13<1:11:51,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  21%|██        | 168/817 [18:19<1:11:40,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  21%|██        | 169/817 [18:26<1:11:14,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  21%|██        | 170/817 [18:32<1:11:02,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  21%|██        | 171/817 [18:39<1:10:57,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  21%|██        | 172/817 [18:46<1:10:58,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  21%|██        | 173/817 [18:52<1:11:07,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  21%|██▏       | 174/817 [18:59<1:11:02,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  21%|██▏       | 175/817 [19:06<1:11:02,  6.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  22%|██▏       | 176/817 [19:12<1:10:42,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  22%|██▏       | 177/817 [19:19<1:10:37,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  22%|██▏       | 178/817 [19:25<1:10:24,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  22%|██▏       | 179/817 [19:32<1:10:10,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  22%|██▏       | 180/817 [19:39<1:10:01,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  22%|██▏       | 181/817 [19:45<1:09:44,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  22%|██▏       | 182/817 [19:52<1:09:35,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  22%|██▏       | 183/817 [19:57<1:06:29,  6.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  23%|██▎       | 184/817 [20:04<1:07:08,  6.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  23%|██▎       | 185/817 [20:10<1:07:22,  6.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  23%|██▎       | 186/817 [20:17<1:07:59,  6.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  23%|██▎       | 187/817 [20:23<1:08:09,  6.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  23%|██▎       | 188/817 [20:30<1:08:31,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  23%|██▎       | 189/817 [20:37<1:08:34,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  23%|██▎       | 190/817 [20:43<1:08:45,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  23%|██▎       | 191/817 [20:50<1:08:34,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  24%|██▎       | 192/817 [20:57<1:08:42,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  24%|██▎       | 193/817 [21:03<1:08:41,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  24%|██▎       | 194/817 [21:10<1:08:29,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  24%|██▍       | 195/817 [21:16<1:08:22,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  24%|██▍       | 196/817 [21:23<1:08:13,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  24%|██▍       | 197/817 [21:30<1:08:18,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  24%|██▍       | 198/817 [21:36<1:08:03,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  24%|██▍       | 199/817 [21:43<1:07:55,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  24%|██▍       | 200/817 [21:49<1:07:45,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  25%|██▍       | 201/817 [21:56<1:07:43,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  25%|██▍       | 202/817 [22:02<1:07:32,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  25%|██▍       | 203/817 [22:09<1:07:27,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  25%|██▍       | 204/817 [22:16<1:07:21,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  25%|██▌       | 205/817 [22:22<1:07:12,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  25%|██▌       | 206/817 [22:29<1:07:11,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  25%|██▌       | 207/817 [22:35<1:07:03,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  25%|██▌       | 208/817 [22:42<1:06:44,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  26%|██▌       | 209/817 [22:49<1:06:33,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  26%|██▌       | 210/817 [22:55<1:06:31,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  26%|██▌       | 211/817 [23:02<1:06:17,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  26%|██▌       | 212/817 [23:08<1:06:23,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  26%|██▌       | 213/817 [23:15<1:06:14,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  26%|██▌       | 214/817 [23:21<1:06:15,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  26%|██▋       | 215/817 [23:28<1:06:06,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  26%|██▋       | 216/817 [23:35<1:06:18,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  27%|██▋       | 217/817 [23:41<1:06:17,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  27%|██▋       | 218/817 [23:48<1:06:07,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  27%|██▋       | 219/817 [23:55<1:06:00,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  27%|██▋       | 220/817 [24:01<1:05:39,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  27%|██▋       | 221/817 [24:08<1:05:29,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  27%|██▋       | 222/817 [24:14<1:05:23,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  27%|██▋       | 223/817 [24:21<1:05:26,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  27%|██▋       | 224/817 [24:28<1:05:13,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  28%|██▊       | 225/817 [24:34<1:05:21,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  28%|██▊       | 226/817 [24:41<1:05:17,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  28%|██▊       | 227/817 [24:48<1:05:16,  6.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  28%|██▊       | 228/817 [24:54<1:05:12,  6.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  28%|██▊       | 229/817 [25:01<1:04:56,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  28%|██▊       | 230/817 [25:07<1:04:50,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  28%|██▊       | 231/817 [25:14<1:04:33,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  28%|██▊       | 232/817 [25:21<1:04:32,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  29%|██▊       | 233/817 [25:27<1:04:13,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  29%|██▊       | 234/817 [25:34<1:04:07,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  29%|██▉       | 235/817 [25:40<1:03:53,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  29%|██▉       | 236/817 [25:47<1:03:41,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  29%|██▉       | 237/817 [25:53<1:03:31,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  29%|██▉       | 238/817 [26:00<1:03:27,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  29%|██▉       | 239/817 [26:07<1:03:39,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  29%|██▉       | 240/817 [26:13<1:03:31,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  29%|██▉       | 241/817 [26:20<1:03:21,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  30%|██▉       | 242/817 [26:26<1:03:05,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  30%|██▉       | 243/817 [26:33<1:03:03,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  30%|██▉       | 244/817 [26:40<1:02:50,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  30%|██▉       | 245/817 [26:46<1:02:43,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  30%|███       | 246/817 [26:53<1:02:39,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  30%|███       | 247/817 [26:59<1:02:32,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  30%|███       | 248/817 [27:06<1:02:20,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  30%|███       | 249/817 [27:13<1:02:17,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  31%|███       | 250/817 [27:19<1:02:09,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  31%|███       | 251/817 [27:26<1:01:59,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  31%|███       | 252/817 [27:32<1:02:02,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  31%|███       | 253/817 [27:39<1:01:50,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  31%|███       | 254/817 [27:45<1:01:53,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  31%|███       | 255/817 [27:52<1:01:50,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  31%|███▏      | 256/817 [27:59<1:01:39,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  31%|███▏      | 257/817 [28:05<1:01:31,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  32%|███▏      | 258/817 [28:12<1:01:29,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  32%|███▏      | 259/817 [28:18<1:01:18,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  32%|███▏      | 260/817 [28:25<1:01:00,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  32%|███▏      | 261/817 [28:32<1:00:54,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  32%|███▏      | 262/817 [28:38<1:00:41,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  32%|███▏      | 263/817 [28:45<1:00:34,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  32%|███▏      | 264/817 [28:51<1:00:25,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  32%|███▏      | 265/817 [28:58<1:00:25,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  33%|███▎      | 266/817 [29:04<1:00:17,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  33%|███▎      | 267/817 [29:11<1:00:18,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  33%|███▎      | 268/817 [29:18<1:00:16,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  33%|███▎      | 269/817 [29:24<1:00:16,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  33%|███▎      | 270/817 [29:31<1:00:07,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  33%|███▎      | 271/817 [29:37<1:00:02,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  33%|███▎      | 272/817 [29:44<59:55,  6.60s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  33%|███▎      | 273/817 [29:51<59:40,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  34%|███▎      | 274/817 [29:57<59:49,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  34%|███▎      | 275/817 [30:04<59:38,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  34%|███▍      | 276/817 [30:10<59:28,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  34%|███▍      | 277/817 [30:17<59:11,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  34%|███▍      | 278/817 [30:23<59:10,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  34%|███▍      | 279/817 [30:30<59:01,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  34%|███▍      | 280/817 [30:37<58:58,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  34%|███▍      | 281/817 [30:43<58:45,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  35%|███▍      | 282/817 [30:50<58:43,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  35%|███▍      | 283/817 [30:56<58:48,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  35%|███▍      | 284/817 [31:03<58:43,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  35%|███▍      | 285/817 [31:10<58:36,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  35%|███▌      | 286/817 [31:16<58:29,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  35%|███▌      | 287/817 [31:23<58:26,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  35%|███▌      | 288/817 [31:30<58:24,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  35%|███▌      | 289/817 [31:36<58:21,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  35%|███▌      | 290/817 [31:43<58:09,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  36%|███▌      | 291/817 [31:49<58:02,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  36%|███▌      | 292/817 [31:56<57:49,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  36%|███▌      | 293/817 [32:03<57:38,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  36%|███▌      | 294/817 [32:09<57:34,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  36%|███▌      | 295/817 [32:16<57:23,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  36%|███▌      | 296/817 [32:22<57:24,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  36%|███▋      | 297/817 [32:29<57:02,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  36%|███▋      | 298/817 [32:36<56:54,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  37%|███▋      | 299/817 [32:42<56:42,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  37%|███▋      | 300/817 [32:49<56:43,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  37%|███▋      | 301/817 [32:55<56:42,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  37%|███▋      | 302/817 [33:02<56:31,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  37%|███▋      | 303/817 [33:09<56:40,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  37%|███▋      | 304/817 [33:15<56:27,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  37%|███▋      | 305/817 [33:22<56:18,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  37%|███▋      | 306/817 [33:28<56:02,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  38%|███▊      | 307/817 [33:35<55:55,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  38%|███▊      | 308/817 [33:41<55:47,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  38%|███▊      | 309/817 [33:48<55:45,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  38%|███▊      | 310/817 [33:55<55:33,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  38%|███▊      | 311/817 [34:01<55:32,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  38%|███▊      | 312/817 [34:08<55:27,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  38%|███▊      | 313/817 [34:14<55:20,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  38%|███▊      | 314/817 [34:21<54:35,  6.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  39%|███▊      | 315/817 [34:27<54:33,  6.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  39%|███▊      | 316/817 [34:34<54:50,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  39%|███▉      | 317/817 [34:41<54:46,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  39%|███▉      | 318/817 [34:47<54:37,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  39%|███▉      | 319/817 [34:54<54:29,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  39%|███▉      | 320/817 [35:00<54:26,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  39%|███▉      | 321/817 [35:07<54:23,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  39%|███▉      | 322/817 [35:13<54:11,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  40%|███▉      | 323/817 [35:20<54:10,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  40%|███▉      | 324/817 [35:27<53:58,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  40%|███▉      | 325/817 [35:33<53:48,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  40%|███▉      | 326/817 [35:40<53:40,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  40%|████      | 327/817 [35:46<53:36,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  40%|████      | 328/817 [35:53<53:32,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  40%|████      | 329/817 [35:59<53:22,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  40%|████      | 330/817 [36:06<53:11,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  41%|████      | 331/817 [36:12<53:18,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  41%|████      | 332/817 [36:19<53:15,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  41%|████      | 333/817 [36:26<53:08,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  41%|████      | 334/817 [36:32<52:58,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  41%|████      | 335/817 [36:39<52:52,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  41%|████      | 336/817 [36:45<52:50,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  41%|████      | 337/817 [36:52<52:43,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  41%|████▏     | 338/817 [36:53<39:52,  5.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  41%|████▏     | 339/817 [37:00<43:34,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  42%|████▏     | 340/817 [37:06<46:04,  5.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  42%|████▏     | 341/817 [37:13<48:00,  6.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  42%|████▏     | 342/817 [37:20<49:02,  6.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  42%|████▏     | 343/817 [37:26<49:50,  6.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  42%|████▏     | 344/817 [37:33<50:24,  6.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  42%|████▏     | 345/817 [37:39<50:39,  6.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  42%|████▏     | 346/817 [37:46<50:51,  6.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  42%|████▏     | 347/817 [37:52<50:55,  6.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  43%|████▎     | 348/817 [37:59<51:03,  6.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  43%|████▎     | 349/817 [38:06<51:02,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  43%|████▎     | 350/817 [38:12<51:04,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  43%|████▎     | 351/817 [38:19<51:05,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  43%|████▎     | 352/817 [38:25<51:05,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  43%|████▎     | 353/817 [38:28<41:59,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  43%|████▎     | 354/817 [38:35<44:38,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  43%|████▎     | 355/817 [38:41<46:26,  6.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  44%|████▎     | 356/817 [38:48<47:44,  6.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  44%|████▎     | 357/817 [38:55<48:30,  6.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  44%|████▍     | 358/817 [39:01<48:53,  6.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  44%|████▍     | 359/817 [39:08<49:08,  6.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  44%|████▍     | 360/817 [39:14<49:14,  6.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  44%|████▍     | 361/817 [39:21<49:05,  6.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  44%|████▍     | 362/817 [39:27<49:05,  6.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  44%|████▍     | 363/817 [39:34<49:01,  6.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  45%|████▍     | 364/817 [39:40<49:00,  6.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  45%|████▍     | 365/817 [39:47<49:02,  6.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  45%|████▍     | 366/817 [39:53<49:07,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  45%|████▍     | 367/817 [40:00<49:11,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  45%|████▌     | 368/817 [40:07<48:59,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  45%|████▌     | 369/817 [40:13<49:00,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  45%|████▌     | 370/817 [40:20<48:57,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  45%|████▌     | 371/817 [40:26<48:58,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  46%|████▌     | 372/817 [40:33<48:53,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  46%|████▌     | 373/817 [40:40<48:54,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  46%|████▌     | 374/817 [40:46<48:51,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  46%|████▌     | 375/817 [40:53<48:40,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  46%|████▌     | 376/817 [40:59<48:33,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  46%|████▌     | 377/817 [41:06<48:24,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  46%|████▋     | 378/817 [41:13<48:23,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  46%|████▋     | 379/817 [41:19<48:14,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  47%|████▋     | 380/817 [41:26<48:09,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  47%|████▋     | 381/817 [41:32<47:57,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  47%|████▋     | 382/817 [41:39<47:49,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  47%|████▋     | 383/817 [41:46<47:36,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  47%|████▋     | 384/817 [41:52<47:35,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  47%|████▋     | 385/817 [41:59<47:34,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  47%|████▋     | 386/817 [42:05<47:27,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  47%|████▋     | 387/817 [42:12<47:31,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  47%|████▋     | 388/817 [42:19<47:23,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  48%|████▊     | 389/817 [42:25<47:23,  6.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  48%|████▊     | 390/817 [42:32<47:06,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  48%|████▊     | 391/817 [42:39<47:06,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  48%|████▊     | 392/817 [42:45<46:57,  6.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  48%|████▊     | 393/817 [42:52<46:47,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  48%|████▊     | 394/817 [42:58<46:35,  6.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  48%|████▊     | 395/817 [43:05<46:24,  6.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  48%|████▊     | 396/817 [43:12<46:12,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  49%|████▊     | 397/817 [43:18<46:03,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  49%|████▊     | 398/817 [43:25<45:56,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  49%|████▉     | 399/817 [43:31<45:51,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  49%|████▉     | 400/817 [43:38<45:46,  6.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  49%|████▉     | 401/817 [43:44<45:34,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  49%|████▉     | 402/817 [43:49<40:48,  5.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  49%|████▉     | 403/817 [43:55<42:05,  6.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  49%|████▉     | 404/817 [44:02<42:59,  6.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  50%|████▉     | 405/817 [44:08<43:29,  6.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  50%|████▉     | 406/817 [44:15<43:53,  6.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  50%|████▉     | 407/817 [44:22<44:01,  6.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  50%|████▉     | 408/817 [44:28<44:15,  6.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  50%|█████     | 409/817 [44:35<44:27,  6.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  50%|█████     | 410/817 [44:41<44:30,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  50%|█████     | 411/817 [44:48<44:27,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  50%|█████     | 412/817 [44:55<44:19,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  51%|█████     | 413/817 [45:01<44:16,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  51%|█████     | 414/817 [45:08<44:07,  6.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  51%|█████     | 415/817 [45:14<44:05,  6.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  51%|█████     | 416/817 [45:21<43:47,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  51%|█████     | 417/817 [45:27<43:40,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  51%|█████     | 418/817 [45:34<43:36,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  51%|█████▏    | 419/817 [45:41<43:31,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  51%|█████▏    | 420/817 [45:47<43:20,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  52%|█████▏    | 421/817 [45:54<43:14,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  52%|█████▏    | 422/817 [46:00<43:06,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Evaluating:  52%|█████▏    | 423/817 [46:07<43:02,  6.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "config = load_config()\n",
        "tokenizer = prepare_tokenizer(config)\n",
        "model = load_model(config)\n",
        "tokenized_validation, raw_validation = prepare_dataset(tokenizer, config)\n",
        "evaluate_model(model, tokenizer, raw_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59R0jNMhPEnG"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b20c96fc8b924086adcefb42e00ae2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdb4bb7b0a7946468b8f9cb57838cb36",
              "IPY_MODEL_3e60643c48d5416aa4df450e3f64a820",
              "IPY_MODEL_af220d5076d443e7a49f1f5bdcab56e5"
            ],
            "layout": "IPY_MODEL_042e06bc75b048fe83bec11f5e9083f9"
          }
        },
        "cdb4bb7b0a7946468b8f9cb57838cb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85475c51c6da4d098cb9520724186b9c",
            "placeholder": "​",
            "style": "IPY_MODEL_59f74af3607e49568940e92eda8dee02",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3e60643c48d5416aa4df450e3f64a820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31fffa461acf4e2fb22f050100aa772d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdf69a78f7b4470fb90bef324ebd1db9",
            "value": 2
          }
        },
        "af220d5076d443e7a49f1f5bdcab56e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71468b43f8c14c7c8df7b975eab51cea",
            "placeholder": "​",
            "style": "IPY_MODEL_2ed11fc1c51343b0aec0eeb5206fac34",
            "value": " 2/2 [00:16&lt;00:00,  7.71s/it]"
          }
        },
        "042e06bc75b048fe83bec11f5e9083f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85475c51c6da4d098cb9520724186b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59f74af3607e49568940e92eda8dee02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31fffa461acf4e2fb22f050100aa772d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf69a78f7b4470fb90bef324ebd1db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71468b43f8c14c7c8df7b975eab51cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ed11fc1c51343b0aec0eeb5206fac34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e9cc19ed25a4a7daaeef79206401df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6cb0840320a4ae9a2f1b5cbbd6355a0",
              "IPY_MODEL_3b98693a4e0044cc8418ec3d03202f6a",
              "IPY_MODEL_bd5e4865c7784eec8b47551b15def170"
            ],
            "layout": "IPY_MODEL_7de49f8406764110a582df3fa1ab99bf"
          }
        },
        "e6cb0840320a4ae9a2f1b5cbbd6355a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48a6984ae23c42f98c606decece65a82",
            "placeholder": "​",
            "style": "IPY_MODEL_c80025d206c24dc5ae2d27150c02c456",
            "value": "Map: 100%"
          }
        },
        "3b98693a4e0044cc8418ec3d03202f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4e900527f464c489b11ad0f83d6d275",
            "max": 817,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a5579d217b14066b7ff58a3093e1cd6",
            "value": 817
          }
        },
        "bd5e4865c7784eec8b47551b15def170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cd59236b9f2409a8acee19c010773f3",
            "placeholder": "​",
            "style": "IPY_MODEL_127046adb4b74f49bf584d4883ebce4e",
            "value": " 817/817 [00:00&lt;00:00, 4470.09 examples/s]"
          }
        },
        "7de49f8406764110a582df3fa1ab99bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a6984ae23c42f98c606decece65a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c80025d206c24dc5ae2d27150c02c456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4e900527f464c489b11ad0f83d6d275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5579d217b14066b7ff58a3093e1cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cd59236b9f2409a8acee19c010773f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127046adb4b74f49bf584d4883ebce4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}